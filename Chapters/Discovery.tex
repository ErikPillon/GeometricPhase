% !TeX encoding = UTF-8
% !TeX spellcheck = en_US

\chapter{Berry discovery of 1983-84}
Berry discovery of 1983-84\footnote{We say 1983-1984 since the original work was apparently submitted in 1983 but was at first instance rejected. However a preprint of his work must have been around since in 1983 another work on the Berry Phase appeared on Physical Review Letter. That's why sometimes the date can be misleading.} was a new discovery on the context about adiabatic of quantum mechanics and this work initiated a lot of work worldwide. In Berry's derivation several independent assumptions were made: initially this phase was called the Berry Phase for everyone but over time this name changed to geometric phase and as we'll see this concept is relevant also in classical wave-optical situations. It's quite remarkable that there are some chances that this concept can be used in condensed matter context. On the other hand we hope that the way we're presenting this work can naturally point out the applications.

As we said many work have been done to relax the assumptions that Berry done in order to defend Berry's work under more general conditions. The first important step was taken by \citet{aharonov1987phase}.
The second important by S and A was taken in 1988 and a third successful step was taken in 1993 and these are the successful and successive steps we'll describe. Apart from these improvements, people were also looking for earlier litteratures from different ideas much earlier then Berry. There are several of them but the most important we will touch upon is the on of Pancharatnam\citet{pancharatnam1956generalized} in 1957, that is, 27 earlier than Berry work. The fact that the work of Pancharatnam was in the direction of the geometric phase was pointed out by ... and ... in 1986. The other important early work relevant in this subject was the one of Bargman and Valentine in 1964 mostly 20 years before Berry working on discuss inf Wigner theorem of 1931, a theorem that Wigner had proved on how symmetric operators can be represented in quantum mechanics. So the th itself is very early (1931); many people had tried to give alternative proof of Wigner Theorem and one very important is given by Bargman in 1964, particularly elegant. The fact that Bargman work was important in the discovery of the Berry phase was pointed out and exploited by Syman and auth. in 1993

These lectures will describe all these thing and more mathematical relevant structures in a more chronological structures, but will not be strictly chronological rigorous. You'll find that many features of QM which we we might be familiar with they will be re examined, re-defined from the geometrical phase pov. When we will come to the kinematic approach we will define some applications. This should give an overview and an idea of the scope of these lectures.   
\section{Simplified Form}
We are now going to present the original Berry's work in a slightly simplified way. 

Having a quantum mechanical system in mind and a general setting, we will mainly deal with pure states $ \Hilbert $ with a time dependent Hamiltonian $ \Ham(t) $ governing the system and we have a state vector describing the system $ \psi(t) $.
The \wf must satisfy all times the (time dependent) \Sch equation 
\begin{equation}
i\hbar \ddt\psi(t)=\Ham(t)\psi(t)
\label{eq:2.1}
\end{equation}
If the Hamiltonian had be time independent, a formal solution of the \Sch equation would be easy to find because what we have to do is to formally take the Hamiltonian, find a basis of our Hilbert space $ \Hilbert $ by diagonalizing the Hamiltonian in its eigenfunctions and eigenvalues and express our \wf as a linear combination of the basis element
\begin{equation}
\Ham \psi_n=E_n\psi_n, \quad n=1,2,\dots \qquad E_n \text{ real}. 
\end{equation}
For simplicity let us assume the spectrum to be discrete, non degenerate as well as constant in time (we already know, though, $ E_n $ to be all real, because of the hermiticity of the Hamiltonian).

What one has to do, then, in general, is to express the solution of the \Sch equation $ \psi $ as a linear combination of the eigenfunctions of the Hamiltonian and for each element add its evolution in time \begin{equation}
\psi=\sum_n c_n\psi_n\to \psi(t)=\sum_n c_n e^{-iE_nt/\hbar}\psi_n.
\label{eq:2.3}
\end{equation}
In principal this procedure is easy and really straightforward. 
%\begin{equation}
%\Ham(t)\psi_n(t)=E_n\psi_n(t), \quad n=1,2,\dots \qquad E_n \text{ real}
%\end{equation}
$ \psi_n $ are called the \emph{stationary states} of the system and of course the $ \psi_n $ form a complete set of orthonormal vector basis
\begin{align}
	\sum_n \Ket{\psi_n}\Bra{\psi_n}=\mathds{1}\\
	\left(\psi_n,\psi_k\right) = \delta_{nk}
\end{align}
where each $ \psi_n $ is defined up to an independent phase factor.

Let us now discuss the case of a time dependent Hamiltonian: generalizing what written above
\begin{equation}
\Ham(t) \psi(t)_n=E_n(t)\psi_n(t), \quad n=1,2,\dots \qquad E_n(t) \text{ real} 
\end{equation}
and as the Hamiltonian changes in time, then its eigenvalues do. Of course at each time the eigenvalues form again a complete orthonormal set.
\begin{rem}
	Every eigenfunction $ \psi_n(t) $ is obtained now by diagonalizing at each time $ t $ the the Hamiltonian $ \Ham(t) $. Even if $ \psi_n(t) $ are not anymore stationary states, the definition  of the eigenfunctions still holds up to a time dependent phase factor. This factor can be both dependent on time and on $ n $.
\end{rem}
Now, there is no hope to recover the exact solution, even though you have solved the eigenvalue problem for each time. What we can do is to generalize eq.\eqref{eq:2.3} with
\begin{equation}
\psi(t)=\sum_n c_n(t)e^{-\frac{i}{\hbar}\int_{0}^{t}E_n(t')\diff t'}\psi_n(t)
\label{eq:2.4}
\end{equation}
and it will reduce to \eqref{eq:2.3} in the case of time independence.

Now plugging \eqref{eq:2.4} in \eqref{eq:2.1} we get 
\begin{align}
i\hbar\sum_n\left(\dot{c_n}(t)\psi_n(t)-\frac{i}{\hbar}c_n(t)E_n(t)\psi_n(t)+c_n(t)\dot{\psi_n}(t) \right)e^{-\frac{i}{\hbar}\int_{0}^{t}E_n(t')\diff t'}\\
=c_n(t)E_n(t)\psi_n(t)e^{-\frac{i}{\hbar}\int_{0}^{t}E_n(t')\diff t'}
\end{align}
so, erasing the equal terms, we obtain
\begin{align}
\sum_n\left(\dot{c_n}(t)\psi_n(t)+c_n(t)\dot{\psi_n}(t) \right)e^{-\frac{i}{\hbar}\int_{0}^{t}E_n(t')\diff t'}=0.
\label{eq:2.5}
\end{align}
and now we take the scalar product with the vector $ \psi_k(t) $
\begin{equation}
\dot{c}_k=-\sum_n c_k(t)e^{-\frac{i}{\hbar}\int_{0}^{t}(E_n(t')-E_k(t'))\diff t'} \left(\psi_k(t),\dot{\psi}_n(t) \right) \qquad \forall k 
\end{equation}
\begin{rem}
	The last equation is exact! There are no approximations involved so far!
\end{rem}

Let's focus for the moment on the term $ \left(\psi_k(t),\dot{\psi}_n(t) \right) $

\begin{equation}
\Ham(t) \psi(t)_n=E_n(t)\psi_n(t), \quad n=1,2,\dots  
\end{equation}
and we differentiate with respect to time on both sides
\begin{equation}
\left(\pd{}{t}\Ham(t)\right)\psi_n(t) +\Ham(t)\dot{\psi}_n(t)=\left(\pd{}{t}E_n(t)\right)\psi_n(t)+E_n(t)\dot{\psi}_n(t)
\end{equation}
and again we take again the scalar product with a generic state $ \psi_k(t) $
\begin{equation}
\left(\psi_k(t),\pd{\Ham(t)}{t}\psi_n(t) \right)+E_k(t)\left(\psi_k(t),\dot{\psi}_n(t) \right)=\dot{E}_n(t)\delta_{nk}+E_n\left(\psi_k(t),\dot{\psi}_n(t) \right)
\end{equation}
so it is appropriate to collect some terms, creating an energy difference, obtaining 
\begin{equation}
\left(E_n(t)-E_k(t)\right)\left(\psi_k(t),\dot{\psi}_n(t) \right)=-\dot{E}_n(t)\delta_{nk}+\left(\psi_k(t),\pd{\Ham(t)}{t}\psi_n(t) \right)\quad \forall k,n
\end{equation}
and the previous result is true in general! There are no approximations involved at all!

If we restrict ourselves at the specific case $ k=n $
\begin{equation}
\dot{E}_n(t)=\left(\psi_n(t),\pd{\Ham(t)}{t}\psi_n(t) \right)
\end{equation}
while in the case $ k\neq n $ we can straightforwardly derive from the eigenvalue problem \footnote{Remember that we assumed non degeneracy in energy spectrum in all the time}
\begin{equation}
\left(\psi_k(t),\dot{\psi}_n(t)\right)=\frac{\left(\psi_k(t),\pd{\Ham(t)}{t}\psi_n(t) \right)}{\left(E_n(t)-E_k(t)\right)}
\end{equation}
So we found an explicit expression relating the relative energy gap in time, the time derivative of the Hamiltonian and the scalar product of the time derivative of the wavefunction with any other wavefunction. We remark that each time dependent wavefunction $ \psi_n(t) $ is defined up to a phase factor that can depend on $ n $ and may depend on time. With this freedom we are left all alone. 

From the normalization condition $ \left(\psi_n(t),\dot{\psi}_n(t)\right)=1 $ we can already say conclude \[ \Re\left(\psi_n(t),\dot{\psi}_n(t)\right)=0\quad \forall n \]
So from now on we agree to restrict the phase factor to be for each $ n $ such that 
\begin{equation}
\left(\psi_k(t),\dot{\psi}_n(t)\right)=0, \qquad \forall n
\label{eq:requirement}
\end{equation}
\begin{rem}
	Making use of the requirement \eqref{eq:requirement}, the phase freedom is eliminated. Once we chose a phase factor at time $ t=0 $ for $ \psi_n(0) $, no more flexibility is left.
\end{rem}

\begin{align}
\dot{c}_k(t)=&-\sum_{n\neq k}c_n(t)e^{i\int_0^t\omega_{kn}(t')\diff t'} \left(\psi_k(t),\dot{\psi}_n(t)\right) \\
=&\sum_{n\neq k} \frac{c_n(t)}{\hbar\omega_{kn}(t)}e^{i\int_0^t\omega_{kn}(t')\diff t'}\left(\psi_k(t),\pd{\Ham(t)}{t}\psi_n(t) \right) \qquad \forall k 
\label{eq:2.11}
\end{align}
where we defined $ \omega_{kn}(t)=\frac{E_k(t)-E_n(t)}{\hbar} $.
\begin{rem}
	We stress again that Eq.\eqref{eq:2.11} is obtained manipulating the \Sch equation only letting the Hamiltonian to vary in time.
\end{rem}

\subsection{Adiabatic condition}
Now we go to the \emph{adiabatic situation}. The so called \textit{Adiabatic Theorem} is a result originally proven by Born\&Fock in 1928 (see \cite{born1928m} for further readings).

The main assumption we'll do is that the Hamiltonian we're considering is a slowly varying operator, that is to say
\begin{equation}
\pd{\Ham}{t}(t) \text{ is "small"}
\end{equation}
The term "small" will be quantitatively clear later on. Physically, it's reasonable to say that the quantities $ \psi_n(t), E_n(t) $ and $ c_n(t) $ are expected to slowly change in time so the the ordering on the energy levels will be maintained (i.e., no crossing levels are allowed).

Let's then continue with the original work of Fock and Born, back to 1928: suppose to have as initial condition $ \psi(0)=\psi_n(0) $, that is to say that the original initial state is equal to a particular eigenvector of the Hamiltonian at time $ t=0 $. So we have $ c_k(0)=\delta_{kn} $(the same chosen in \eqref{2.12})

Notice that our reasoning is perfectly consistent in the framework of the first order perturbation theory; since the term $ \pd{\Ham}{t} $ is explicitly appearing in \eqref{eq:2.11}, we can neglect the time dependency of all the other terms, having that, for $ k\neq n $, 
\begin{equation}
\dot{c}_k(t)\simeq \dfrac{1}{\hbar\omega_{kn}}e^{i\omega_{kn}t}\left(\psi_k,\pd{\Ham(t)}{t}\psi_n\right)
\end{equation}
while for the $ n $-th term we have $ c_n(t)\simeq 1 $: it starts at 1 and stay fixed for all times. 
The $ \dot{c}_k(t) $ can be instead integrated and 
\begin{equation}
c_k(t)\simeq -\dfrac{i}{\hbar\omega_{kn}^2}\left(e^{i\omega_{kn}t}-1\right)\left(\psi_k,\pd{\Ham(t)}{t}\psi_n\right)
\end{equation}
and so, while the term $ c_n $ remains close to 1, all the other terms start from zero and oscillate in time: 

So,if
\begin{equation}
\frac{1}{\omega_{kn}} \vline\left(\psi_k,\pd{\Ham}{t}(t)\psi_n\right)\vline \ll\hbar\omega_{kn}, \qquad \forall k\neq n
\label{eq:2.14}
\end{equation}
is satisfied, then
\begin{equation}
\psi(t)\simeq e^{-\frac{i}{\hbar}\int_{0}^{t'}E_n(t)\diff t}\psi_n(t)
\end{equation}
and this ends the statement of the adiabatic theorem of quantum mechanics.
\begin{rem}
	Eq.\eqref{eq:2.14} is the quantitative statement of what we mean by "adiabatic condition".
\end{rem}

\subsection{Berry's hypothesis}
Now comes the step taken by Berry; Let's take the hypothesis that the Hamiltonian $ \Ham(t) $ is cyclic, that is, $ \Ham(0)=\Ham(T) $ for some $ T $\footnote{Cyclic condition on the Hamiltonian}.
\begin{center}
	\textbf{Question: How does the approximate solution behave? Are they cyclic in a similar sense?}
\end{center}
Answer: the solution must be cyclic in some sense. Because of the non degeneracy and no crossing levels, we have that the eigenvalues of $ \Ham(T) $ are the same of $ \Ham(0) $ so
\begin{align}
E_n(T)=&E_n(0)\\
\psi(0)=\psi_n(0)\quad\Rightarrow& \quad\psi(T)\simeq e^{-\frac{i}{\hbar}\int_{0}^{T}E_n(t)\diff t}\psi_n(T)
\end{align}
from the Adiabatic Theorem. And now we ask: is this a cyclic solution? The answer is still \textbf{yes} but we have that the equality $ \psi(T)=\psi(0) $ is only true apart from a phase, i.e., 
\begin{equation}
\psi_n(T)=\text{\small (n-dependent phase)}\times\psi_n(0)
\label{eq:2.18}
\end{equation}

Now we stop for a while for commenting the following statements: \footnote{They're all approximate in the sense of the adiabatic theorem, but we put the equality sign with no confusion}. 
\begin{empheq}[box=\fbox]{align}
	\psi_n(T)&=e^{i\phi_{geom}^{(n)}}\psi_n(0)\label{eq:geometric_phase}\\
	\psi(T)&\simeq e^{-\frac{i}{\hbar}\int_{0}^{T}E_n(t)\diff t+i\phi_{geom}^{(n)}}\psi_n(0) = e^{i\phi_{tot}^{(n)}}\psi(0) \quad i.e.,\phi_{tot}^{(n)}=\mathrm{arg}\left(\psi(0),\psi(T)\right)\label{eq:total_phase}\\
	\phi_{tot}^{(n)}&=\phi_{geom}^{(n)}+\phi_{dyn}^{(n)} \qquad i.e. \qquad 
	\phi_{geom}^{(n)}=\phi_{tot}^{(n)}-\phi_{dyn}^{(n)}
	\label{eq:Berry_discovery}
\end{empheq}
where we defined 
\begin{equation}
\phi_{dyn}^{(n)}=-\dfrac{i}{\hbar}\int_{0}^TE_n(t)\diff t
\end{equation}
So, in the end, this is the original work of Berry presented in a slightly different language.
\begin{rem}
	Eq. \eqref{eq:geometric_phase} defines how every phase of every wavefunction evolves in time provided that condition \eqref{eq:requirement} is  satisfied. We recall that \eqref{eq:requirement} is only a convention: given the general expression for $ (\psi_k,\dot{\psi}_{n}) $ in the particular case $ k=n $, there's no way for controlling the generic phase between those two, but if \eqref{eq:requirement} is satisfied, then a formula like \eqref{eq:geometric_phase} must exist.
		
	Eq. \eqref{eq:Berry_discovery} (and Eq. \eqref{eq:total_phase} as well) is regarded as the original discovery of Berry. Eq. \eqref{eq:total_phase} is a consequence of the adiabatic theorem, the assumption we made in \eqref{eq:requirement} and the cyclicity condition of the Hamiltonian. If there are no degeneracies and no crossing levels, then every  approximate solution given by the adiabatic condition will also be cyclic. 
\end{rem}
\begin{rem}
	One could argue that changing the convention \eqref{eq:requirement} then the definition for \eqref{eq:geometric_phase} must change. This is absolutely reasonable, but nonetheless we will see that the geometric phase will not change under different assumptions: this \emph{invariance} is one of the most important properties of the Berry Phase. 
\end{rem}

% ---------------------------------------------
\section{Berry original derivation with parameter space}
We want now to present the work performed by Berry in his original work in 1983 (see \cite{berry1985classical}) in the spirit of the parameter space.

The original assumption was that the Hamiltonian, apart from being hermitian, depends on a set of \emph{real} external parameters, let's say $ \rp $, that is $ \Ham\equiv\Ham(\rp) $ with $ \rp $ belonging to a multidimensional real parameter space.
Then Berry imagined the following situation: 
suppose to have a spin $ \frac{1}{2} $ particle immersed in a magnetic field, which is parametrically dependent on time. Imagine then the real parameter space being slowly dependent in time, that is to say, $ \rp $ itself to be time dependent, so that the magnetic field, and the Hamiltonian as well, to be explicitly time dependent $ \Ham(\rp(t)) $. The parameter now that varies adiabatically is of course $ \rp(t) $.
%\begin{rem}
%	We recall that $ \rp(t) $ is a set of real independent parameters and thanks to the Adiabatic condition the quantity $ \pd{\rp}{t} $ is small.
%\end{rem}
We will denote the closed loop in the parameter space by
\begin{equation}
\mathcal{C}=\left\{\rp(t)\mid 0\leq t\leq T \right\}
\label{eq:Curve_C}
\end{equation}
where we assumed $ \rp(0)=\rp(T) $.

\textbf{Figure missing! Place here as soon as possible!}

The curve $ \mathcal{C} $ is the curve traced by $ \rp(t) $ letting $ t $ varying. $ \mathcal{C} $ is of course cyclic.
The curve $ \mathcal{C} $ is then our domain of interest and for each point in $ \mathcal{C} $ we have an associated Hamiltonian.
\begin{align}
\Ham(t)\Ket{n;\rp}=E_n(\rp)\Ket{n;\rp}\\
\Braket{n';\rp|n;\rp}=\delta_{n'n}
\end{align}
and we have of course an orthonormal basis at each point of the multidimensional parameters space.
\begin{rem}
	To be precise, we should refer to the eigenvalues $ E_{n}(\rp) $ not as eigenvalues of the Hamiltonian but as \emph{eigenvalues of the Hamiltonian at a certain point $ \rp $ of the parameter space}. We recall moreover that each wavefunction $ \Ket{n;\rp} $ is defined up to a phase factor that may depend on $ n $ and on $ \rp. $ 
\end{rem}
\begin{rem}
	Thanks to the non degeneracy of the eigenvalues of the Hamiltonian, we have no ambiguity in defining the eigenvectors of the Hamiltonian, that is to say, there are not crossing levels of energy. Let's say for example that we start from the point $ \rp(0) $ in tha parameter space, then we can recover a set of well defined single valued wavefunctions for the Hamiltonian $ \Ham(\rp(0)) $. Letting now $ t $ varying from $ 0 $ to $ T $ we have a complete set of well defined single valued vawefunctions for every point and when $ t=T $ we have the same set of eigenfunctions as we had in $ t=0. $ Each eigenfucntion remains, anyway, defined up to an arbitrary phase. 
\end{rem}

At this stage Berry recover the Adiabatic Theorem and tries to solve the classical \Sch equation in the case in which the initial state is the $ n $-th eigenstate of the Hamiltonian at $ t=0 $:
\begin{equation}
\begin{cases}
i\hbar\dot{\psi}(t)=\Ham(\rp(t))\psi(t)\\
\psi(0)=\Ket{0;\rp(0)}
\end{cases}
\end{equation}
which, for intermediate times, within the validity of the Adiabatic Theorem, gives the solution
\begin{equation}
\psi(t)\simeq e^{-\frac{i}{\hbar}\int_{0}^{t}E_n(\rp(t'))\diff t'+\gamma_n(t)}\Ket{n;\rp(t)}
\label{eq:gen_solution}
\end{equation}
and we easily see that $ \gamma_n(0)=0, $ since it has to match with the initial condition.

The first term in the exponential of eq.\eqref{eq:gen_solution} is the \emph{dynamical phase} while the term $ \gamma_n(t) $ is the geometric phase. This latter phase is non integrable and so far we are not ready to handle it.

So the next step to take is to take the (general) solution \eqref{eq:gen_solution}, to plug it into the \Sch equation itself and try to extract an equation for $ \gamma_n(t) $.
%% --------- Second Lecture ------------
%From the initial condition $ \psi(0)=\psi_n(0) $ we have
%\begin{equation}
%\psi(t)=\sum_{n'}c_{n'}(t)e^{-\frac{i}{\hbar}\int_{0}^{t}E_n(t')\diff t'}\psi_{n'}(t)
%\end{equation}
%
%Then, if $ n'\neq n $, $ \dot{c}_n(t)\simeq 0 $ if $ \abs{\left(\psi_{n'},\pd{\Ham}{t}(t)\psi_n \right) }<<(E_{n'}-E_{n})/\hbar, $
%then we have $ \dot{c}_n(t)\simeq0, c_n(t)\simeq 1. $ And so this means that the \Sch solution takes the form of:
%\begin{equation}
%\psi(t)\simeq e^{-\frac{i}{\hbar}\int_{0}^{t}E_n(t')\diff t'}\psi_{n'}(t) \xrightarrow[t\to T]{} e^{-\frac{i}{\hbar}\int_{0}^{T}E_n(t)\diff t}\psi_{n}(t)\underbrace{\psi_n(T)}_{e^{i\phi_{geom}^{(n)}}\psi_n(0)}
%\end{equation}
%
%\begin{equation}
%\psi(T)\simeq \underbrace{e^{i\phi_{tot}^{(n)}}}_{\underbrace{e^{\frac{i}{\hbar}\int_{0}^{T}E_n(t)\diff t}}_{\text{dyn}}\times\underbrace{e^{i\phi_{geom}^{(n)}}}_{\text{geom}}}\psi(0).
%\end{equation}
%
\begin{rem}
	The set $ \Ket{n;\rp} $ form a set of single-valued eigenvectors in the parameter space. Pay attention that this condition is the crucial difference in spirit with the derivation given in the previous section. There the original assumption was to put $ \left(\psi_n(t),\dot{\psi}_n(t) \right) $ in order to eliminate any arbitrary freedom on the choice of the initial wavefunction.
\end{rem}

%Suppose to have the following situation: $ \psi(0)=\Ket{n,\rp(0)} $, that is, the initial condition is in one of the eigenstates for the Hamiltonian.  Its time evolution is then defined by
%\begin{equation}
%\begin{cases}
%\psi(t)\simeq e^{-\frac{i}{\hbar}\int_{0}^{t}E_n(\rp(t'))\diff t'+i\gamma_n(t)}\Ket{n;\rp(t)}\\
%\gamma_n(t)=0
%\end{cases}
%\end{equation}

\begin{rem}
	What Berry did is the following: he applied the Adiabatic Theorem and obtained an approximated solution for $ \psi(t) $. He then put $ \psi(t) $ itself into the \Sch Equation and derived an equation of motion for $ \gamma_n(t) $
\end{rem}

So, putting eq.\eqref{eq:gen_solution} into the \Sch equation, is equivalent to write (as a consequence of the Adiabatic Theorem)
\begin{equation}
\dot{\gamma}_n(t)\Ket{n;\rp(t)}\simeq i\ddt \Ket{n,\rp(t)}
\end{equation}
and then sandwiching with a Ket,
\begin{align}
	\dot{\gamma}_n(t)&\simeq i\Bra{n;\rp(t)}\ddt\Ket{n:\rp(t)}\\
	&=i\Bra{n;\rp(t)}\underline{\nabla}\Ket{n;\rp(t)}\dot{\rp}(t)\footnote{We have to stress that by $ \underline{\nabla} $ we mean the "parameter derivative", that is the derivative with respect to the component of the vector $ \rp $}
\end{align}

\begin{rem}
	We notice that the result \begin{equation}
	\dot{\gamma}_n(t)\simeq i\Bra{n;\rp(t)}\ddt\Ket{n:\rp(t)}
	\end{equation}
	is a consequence of the \Sch Equation and not a condition imposed on the system.
\end{rem}
\begin{rem}
	We have $ \Ket{n;\rp(0)}=\Ket{n;\rp(T)} $ since they're globally well defined.
\end{rem}

Performing the circuitation along the curve $ \mathcal{C} $ defined in \eqref{eq:Curve_C}, we have
\begin{equation}
\gamma_n(T)\equiv \gamma_n(0)=i\oint_{\mathcal{C}}\Bra{n;\rp}\underline{\nabla}\Ket{n;\rp}\dot{\rp}(t)\diff t=i\oint_{\mathcal{C}}\Bra{n;\rp}\underline{\nabla}\Ket{n;\rp}\cdot\diff\rp
\label{eq:2.26}\end{equation} 
and this is exactly what we wrote above.

In the end, we see that 
\begin{equation}
\Bra{n;\rp}\underline{\nabla}\Ket{n;\rp}=i\Im\Bra{n;\rp}\underline{\nabla}\Ket{n;\rp}
\label{eq:2.27}
\end{equation}
and so plugging \eqref{eq:2.27} into \eqref{eq:2.26} we obtain
\begin{align}
\gamma_n(\mathcal{C})&=-\Im \oint \Bra{n;\rp}\underline{\nabla}\Ket{n;\rp}\cdot\diff\rp\\
&=-\Im\iint_{\mathcal{S}}\nabla\wedge\Bra{n;\rp}\underline{\nabla}\Ket{n;\rp}\cdot\diff\mathcal{S}\text{\footnotemark}\\
&=-\Im\iint_{\mathcal{S}}\left(\underline{\nabla}\Bra{n;\rp}\right)\wedge\left(\underline{\nabla}\Ket{n;\rp}\right)\cdot\diff\mathcal{S}\\
&= -\Im \iint_{\mathcal{S}}\left(\sum_{m\neq n}\underline{\nabla}\Bra{n;\rp}\right)\Ket{m;\rp}\wedge\Bra{m;\rp}\underline{\nabla}\Ket{n;\rp}
\end{align}
\footnotetext{Following Berry's argument, we are now restricting ourselves in the case in which the parameter space is a 3D space, so the simplest form of Stoke's Theorem can be applied.}
and the term $ m=n $ is neglected since gives a zero contribution: a pure imaginary term times a pure imaginary term gives an only real contribution, so neglected by the operator $ \Im. $

Then from $ \Ham(\rp)\Ket{n;\rp}=E_n(\rp)\Ket{n;\rp} $, applying the gradient operator on both sides, we obtain for $ m\neq n $
\begin{equation}
\Bra{m;\rp}\underline{\nabla}\Ket{n;\rp}=\dfrac{\Bra{m;\rp}\underline{\nabla}\Ham(\rp)\Ket{n;\rp}}{E_n(\rp)-E_m(\rp)}.
\end{equation}
The final result is then
\begin{equation}
\gamma_n(\mathcal{C})=-\iint_{\mathcal{S}}V_n(\rp)\cdot\diff\mathcal{S}
\end{equation}
where we defined $ V_n $ as 
\begin{equation}
V_n(\rp):=\Im\sum_{m\neq n}\dfrac{\Bra{n;\rp}\underline{\nabla}\Ham(\rp)\Ket{m;\rp}\wedge\Bra{m;\rp}\underline{\nabla}\Ham(\rp)\Ket{n;\rp}}{\left(E_n(\rp)-E_m(\rp)\right)^2}
\label{eq:2.31}
\end{equation}
\begin{rem}
	Berry's comment at this stage is that the result does not depend on $ \rp $ since the gradient is only acting on $ \Ham(\rp) $, so it is independent on the choice of the phase of the wavefunction. The final take at home message is then that the geometric phase $ \gamma_n(\mathcal{C}) $ does not depend on the particular choice of the phase of the eigenvector $ \Ket{n;\rp} $ of the Hamiltonian at each point of the parameter space, under the assumption that \emph{the eigenvectors are globally well defined}.
	\label{rem:freedom}
\end{rem}
Remark \ref{rem:freedom} leads to an enormous amount of freedom in the choice of the global phase $ \chi(\rp) $
\begin{equation}
\Ket{n;\rp}\to e^{i\chi(\rp)}\Ket{n;\rp}
\end{equation}
\subsection{Two fold degeneracies}
Let us suppose that we are in the proximity of a two fold degeneracy. By degeneracy we mean that two levels of the Hamiltonian happen to be degenerate of a certain point of the phase space.

%What is the phase in the proximity of a two folds degeneracy?

We can suppose in $ \rp=0 $ we have a degeneracy for the Hamiltonian. So if we are far from zero, we have o problems at all, but if we are close to $ 0, $ we have to work in a different way. The two crossing levels are the most important, so from a Quantum Mechanical point of view, the problem is only a two level problem.
\begin{align}
	\Ham(\underline{0})=0; \qquad & \Ham(\rp)=\Ket{\pm;\rp}=E_{\pm}(\rp)=\Ket{\pm;\rp}\\
	& E_{+}(\rp)>E_-(\rp),\qquad \rp\neq 0\\
	& E_{+}(\underline{0})=E_{-}(\underline{0})=0.
\end{align} 
So, now, without any loss of generality, we can make use of the Pauli Matrices for defining the Hamiltonian to be in the following way
\begin{align}
	\Ham(\rp)=\dfrac{1}{2};\qquad E_{\pm}(\rp)=\pm\dfrac{1}{2}R, \qquad R=\abs{\rp}\\
	\Ket{+;\rp}\Bra{+;\rp}=\dfrac{1}{2}\left(1\pm \hat{R}\cdot\underline{\sigma} \right)\label{eq:2.33}
\end{align}
And so we have to plug \eqref{eq:2.33} into \eqref{eq:2.31}: the summation becomes an only single term and, recognizing that $ E_n(0)-E_m(0)=+\frac{1}{2}R-(-\frac{1}{2}R) $, we obtain 
\begin{equation}
\underline{V}_{+}(\rp)=\frac{R_j}{2R^3}
\label{eq:2.35}
\end{equation}

So now comes the result of Berry: the phase gained by the \wf is exactly given by the integration of \eqref{eq:2.35} and is the solid angle shifted by the curve $ \mathcal{C} $. Berry refereed to this result as the \textit{magnetic field of a "magnetic monopole"}
\begin{equation}
\gamma_{+}(\mathcal{C})=-\dfrac{1}{2}\Omega\left[\mathcal{C}\right], \qquad \Omega\left[\mathcal{C}\right]=\text{solid angle at \underline{0}}
\end{equation}